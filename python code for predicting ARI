import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from pycaret.classification import *
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
import optuna

# Load data
file_path = r'C:\Users\IFAIN-DATA MANAGER\Dropbox\research\ARI\ARI_data.xlsx'
data = pd.read_excel(file_path)

# Draw frequency tables
categorical_vars = ['ARI', 'gender', 'age', 'PCV1', 'PCV2', 'PCV3', 'residence type', 'diarrhoea', 'toilet sharing', 'obese']

for var in categorical_vars:
    plt.figure(figsize=(8, 5))
    sns.countplot(data[var])
    plt.title(f'Frequency Table for {var}')
    plt.show()

# Prepare data for machine learning
X = data[['gender', 'age', 'PCV1', 'PCV2', 'PCV3', 'residence type', 'diarrhoea', 'toilet sharing', 'obese']]
y = data['ARI']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit a binary logistic regression model
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# Fit a decision tree model
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

# Evaluate models
y_pred_lr = lr_model.predict(X_test)
y_pred_dt = dt_model.predict(X_test)

print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr))

print("\nDecision Tree Classification Report:")
print(classification_report(y_test, y_pred_dt))

# Preprocess data using pycaret
clf1 = setup(data, target='ARI', session_id=42)

# Create a model with pycaret
compare_models()

# Imbalanced-learn pipeline
model_pipe = Pipeline([('sampling', SMOTE(random_state=42)),
                       ('classification', LogisticRegression())])

# Hyperparameter tuning using Optuna
def objective(trial):
    # Parameter tuning space
    params = {
        'C': trial.suggest_loguniform('C', 1e-10, 1e10),
    }

    # Model
    model = LogisticRegression(**params)

    # Create pipeline
    pipe = Pipeline([('sampling', SMOTE(random_state=42)), ('classification', model)])

    # Evaluate pipeline
    scores = cross_val_score(pipe, X, y, cv=3, scoring='accuracy')
    return scores.mean()

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Get the best hyperparameters
best_params = study.best_params

# Fit the final model with the best hyperparameters
final_model = LogisticRegression(**best_params)
final_model.fit(X_train, y_train)
